{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from matplotlib.lines import Line2D\n",
    "from shapely.geometry import Point\n",
    "import geopandas\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from imblearn import under_sampling, over_sampling \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "#plt.style.use('dark_background')\n",
    "pd.set_option('display.max_columns',500)\n",
    "sns.set()\n",
    "\n",
    "import random\n",
    "\n",
    "SEED = 111\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "data_path = p.parent.parent / 'data' / 'Master Project Data' \n",
    "nfirs_path =  data_path / 'NFIRS Fire Incident Data.csv'\n",
    "\n",
    "# List the columns you want to download from the NFIRS csv\n",
    "cols_to_use = ['state','fdid','inc_date','oth_inj','oth_death','prop_loss',\n",
    "               'cont_loss','tot_loss','geoid']\n",
    "\n",
    "# Specify particular data type for geoid column\n",
    "col_dtypes = {'geoid':str}\n",
    "\n",
    "# Read in NFIRS dataframe\n",
    "nfirs = pd.read_csv(nfirs_path,\n",
    "                    dtype = col_dtypes,\n",
    "                    usecols = cols_to_use,\n",
    "                    encoding='latin-1')\n",
    "\n",
    "# Convert inc_date column values to python datetime type\n",
    "nfirs['inc_date'] = pd.to_datetime(nfirs['inc_date'], infer_datetime_format=True)\n",
    "\n",
    "#Read in ACS dataframe\n",
    "ACS_path = data_path  / 'ACS 5YR Block Group Data.csv'\n",
    "ACS = pd.read_csv(ACS_path,\n",
    "                  dtype = {'GEOID':'object'},\n",
    "                index_col = 1)\n",
    "\n",
    "#Read in Lives Saved & House Visits dataframes\n",
    "lives_saved_path =  data_path / 'ARC Lives Saved Data.csv'\n",
    "lives_saved = pd.read_csv(lives_saved_path)\n",
    "arc_visits_path =  data_path / 'ARC Response Data.csv'\n",
    "arc_visits = pd.read_csv(arc_visits_path)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NFIRS Munging\n",
    "\n",
    "# Ensure correct calculation of tot_loss column \n",
    "nfirs['tot_loss'] = nfirs['prop_loss'] + nfirs['cont_loss']\n",
    "\n",
    "# Create mask for new severe fire variable\n",
    "sev_fire_mask = (nfirs['oth_death'] > 0) | (nfirs['oth_inj'] > 0) | (nfirs['tot_loss'] >= 10000)\n",
    "\n",
    "# By default assigns values of severe fire column as not severe\n",
    "nfirs['severe_fire'] = 'not_sev_fire'\n",
    "\n",
    "# Applies filter to severe fire column to label the severe fire instances correctly\n",
    "nfirs.loc[sev_fire_mask,'severe_fire'] = 'sev_fire'\n",
    "\n",
    "sev_nfirs = nfirs.loc[sev_fire_mask, :].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for additional nfirs munging\n",
    "def nfirs_munging(nfirs):\n",
    "    \"\"\" apply nfirs munginng\n",
    "\n",
    "    :param nfirs: pandas dataframe\n",
    "\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Create new NFIRS variables based on specified thresholds of existing variables in dataframe\n",
    "    nfirs['had_inj'] = np.where(nfirs['oth_inj']>0,'had_inj','no_inj')\n",
    "    nfirs['had_death'] = np.where(nfirs['oth_death']>0,'had_death','no_death')\n",
    "    nfirs['10k_loss'] = np.where(nfirs['tot_loss']>=10000,'had_10k_loss','no_10k_loss')\n",
    "\n",
    "    # Extract just the numeric portion of the geoid\n",
    "    nfirs['geoid'] =  nfirs['geoid'].str.strip('#_')\n",
    "\n",
    "    # Add a year column to be used to groupby in addition to geoid\n",
    "    nfirs['year'] = nfirs['inc_date'].dt.year.astype('str')\n",
    "    nfirs.set_index('geoid',inplace = True)\n",
    "\n",
    "    return nfirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nfirs = nfirs_munging(nfirs)\n",
    "print('nfirs', nfirs.shape)\n",
    "sev_nfirs = nfirs_munging(sev_nfirs)\n",
    "print('severe nfirs', sev_nfirs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ACS Munging\n",
    "\n",
    "# Ensures GEOID variable is in the correct format and sets it as the dataframe index\n",
    "ACS['GEOID'] = ACS['GEOID'].str[2:]   \n",
    "ACS.set_index(['GEOID'],inplace = True)\n",
    "\n",
    "# Captures name properies of GEOIDs for later use before filtering dataframe to be numeric features only\n",
    "Names = ACS[['county_name', 'state_name']]\n",
    "\n",
    "# Removes extraneous features (i.e. non-numeric) in the dataframe\n",
    "if 'Unnamed: 0' in ACS.columns:\n",
    "    ACS.drop('Unnamed: 0','columns',inplace= True)\n",
    "\n",
    "if 'NAME' in ACS.columns:\n",
    "    ACS.drop('NAME','columns',inplace= True)\n",
    "\n",
    "if 'inc_pcincome' in ACS.columns:\n",
    "    ACS.drop('inc_pcincome','columns',inplace= True)\n",
    "\n",
    "# Creates vector of total populations for each census block to be used to normalize total fires per year variable\n",
    "tot_pop = ACS[['tot_population']]\n",
    "\n",
    "# Drop all total count columns in ACS and keeps all percentage columns\n",
    "cols = ACS.columns.to_list()\n",
    "for col in cols:\n",
    "    if  col.find('tot') != -1 : \n",
    "        ACS.drop(col,'columns', inplace = True)\n",
    "\n",
    "\n",
    "# Integer indexing for all rows, but gets rid of county_name, state_name, and in_poverty\n",
    "ACS = ACS.iloc[:,3:]\n",
    "\n",
    "# Remove missing values from dataframe\n",
    "ACS.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "ACS.dropna(inplace = True)\n",
    "\n",
    "print('ACS', ACS.shape, 'top_pop', tot_pop.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjust total fires per year by the population counts\n",
    "def fires_munging(nfirs):\n",
    "\n",
    "    # Creates dataframe that shows the number of fires in each census block each year\n",
    "    fires =  pd.crosstab(nfirs.index,nfirs['year'])\n",
    "    fires.index.rename('GEOID',inplace = True)\n",
    "\n",
    "    # Grab total population values pulled from ACS dataframe and assign to each census block in NFIRS dataframe\n",
    "    fires = fires.merge(tot_pop, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "    # Remove resulting NaN/infinity values following merge\n",
    "    fires.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "    fires.dropna(inplace = True)\n",
    "\n",
    "    # drop rows with no population count\n",
    "    fires = fires[fires['tot_population'] != 0 ] \n",
    "\n",
    "    # population adjustment\n",
    "    fires.loc[:,'2009':'2016'] = fires.loc[:,'2009':'2016'].div(fires['tot_population'], axis = 'index') * 1000\n",
    "    fires = fires.loc[:,:'2016']\n",
    "\n",
    "    # view fires by year across geoids; displays additional information regarding # of fires in higher percentile categories\n",
    "    fires.describe(percentiles=[.75, .85, .9 ,.95, .99])\n",
    "\n",
    "    # define variables to indicate census blocks in the top 10% percent of fire risk scores\n",
    "    top10 = fires > fires.quantile(.9)\n",
    "\n",
    "    return fires, top10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fires, top10 = fires_munging(nfirs)\n",
    "print(nfirs.shape, fires.shape, top10.shape)\n",
    "sev_fires, sev_top10 = fires_munging(sev_nfirs)\n",
    "print(sev_nfirs.shape, sev_fires.shape, sev_top10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create histogram of with # of fires on x-axis and # of census blocks on y-axis\n",
    "def plotFires(df):\n",
    "\n",
    "    figsize = (20, 16)\n",
    "    cols = 4\n",
    "    rows = 2\n",
    "    f, axs = plt.subplots(cols,rows,figsize= figsize)\n",
    "\n",
    "\n",
    "    cases = df.columns.to_list()\n",
    "    for  case in enumerate(cases):\n",
    "        ax = plt.subplot(cols,rows,case[0]+1)\n",
    "        ax.set_title('All Fires {}'.format(str(case[1])) )\n",
    "        plt.hist(df[case[1]],bins=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,20,40,80,100])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find correlated features in ACS dataset and identify the highly correlated relationships\n",
    "\n",
    "# Create ACS correlation matrix\n",
    "corr = ACS.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "#Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    " \n",
    "# Filtering out lower/upper triangular duplicates \n",
    "corr_high = corr[abs(corr) > 0.7].stack().reset_index()\n",
    "corr_high = corr_high[corr_high['level_0'].astype(str)!=corr_high['level_1'].astype(str)]\n",
    "corr_high['ordered-cols'] = corr_high.apply(lambda x: '-'.join(sorted([x['level_0'],x['level_1']])),axis=1)\n",
    "corr_high = corr_high.drop_duplicates(['ordered-cols'])\n",
    "corr_high.drop(['ordered-cols'], axis=1, inplace=True)\n",
    "corr_high.columns = ['Pair Var 1', 'Pair Var 2', 'Corr Value']\n",
    "\n",
    "# Display highly correlated pairs\n",
    "print(corr_high.sort_values(by=['Corr Value'], ascending=False))\n",
    "\n",
    "# From highly correlated pairs, remove one of the Pair Vars from the ACS dataset except for the 'mort' variables\n",
    "ACS = ACS.drop(['house_pct_vacant', 'did_not_work_past_12_mo', 'house_pct_non_family', 'house_pct_rent_occupied',\n",
    "                           'race_pct_nonwhite', 'race_pct_nonwhitenh', 'house_pct_incomplete_plumb',\n",
    "                           'house_pct_incomplete_kitchen', 'race_pct_whitenh'], axis=1) \n",
    "\n",
    "# Based on feature importance experiments, select features with consistence importance across annual predictions\n",
    "ACS = ACS[['house_yr_pct_earlier_1939', 'house_pct_occupied', 'house_pct_family_married', 'race_pct_black',\n",
    "          'worked_past_12_mo', 'heat_pct_fueloil_kerosene', 'educ_bachelors', 'house_pct_live_alone', \n",
    "          'educ_some_col_no_grad', 'house_pct_ownd_occupied', 'house_w_home_equity_loan', 'house_val_175K_200K',\n",
    "           'house_val_200K_250K']]\n",
    "\n",
    "print (ACS.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upsample or downsample our dataframe features if we have unbalanced classes\n",
    "\n",
    "def resample_df(X,y,upsample=True,seed = SEED):\n",
    "    from sklearn.utils import resample\n",
    "    # check which of our two classes is overly represented \n",
    "    if np.mean(y) > .5:\n",
    "        major,minor = 1,0\n",
    "    else:\n",
    "        major,minor = 0, 1\n",
    "    \n",
    "    # Add Class feature to dataframe equal to our existing dependent variable\n",
    "    X['Class'] = y\n",
    "    \n",
    "    df_major = X[X.Class == major ]\n",
    "    df_minor = X[X.Class == minor ]\n",
    "    \n",
    "\n",
    "    if upsample:      \n",
    "    \n",
    "        df_minor_resampled = resample(df_minor,\n",
    "                                     replace = True,\n",
    "                                     n_samples = df_major.shape[0], \n",
    "                                     random_state = seed)\n",
    "    \n",
    "    \n",
    "   \n",
    "        combined = pd.concat([df_major,df_minor_resampled])\n",
    "        \n",
    "        # Debug\n",
    "        #print('minor class {}, major class {}'.format(df_minor_resampled.shape[0],\n",
    "                                                       #df_major.shape[0]))\n",
    "    \n",
    "        \n",
    "    else: # downsample\n",
    "         \n",
    "        df_major_resampled = resample(df_major,\n",
    "                                     replace = False,\n",
    "                                     n_samples = df_minor.shape[0],\n",
    "                                     random_state = seed)\n",
    "        \n",
    "        \n",
    "        combined = pd.concat([df_major_resampled,df_minor])\n",
    "        \n",
    "        #print('minor class {}, major class {}'.format(df_minor.shape[0],\n",
    "                                                      #df_major_resampled.shape[0]))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    y_out = combined['Class']\n",
    "    X_out = combined.drop('Class', axis =1)\n",
    "    return X_out , y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train model that predicts whether each census block is in the top 10% percent of fire risk scores\n",
    "def train_model(top10,fires, ACS = pd.DataFrame(), nyears = 4, modeltype='LogisticRegression', seed = SEED):\n",
    "    from scipy.stats import zscore\n",
    "    \n",
    "    \n",
    "    # Define model types & parameters \n",
    "    \n",
    "    if modeltype =='LogisticRegression':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        model = LogisticRegression(warm_start=True,\n",
    "                                   class_weight = 'balanced',\n",
    "                                   max_iter = 1000)\n",
    "\n",
    "        \n",
    "    elif modeltype =='BalBagged':\n",
    "        from imblearn.ensemble import BalancedBaggingClassifier\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        model = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                          n_estimators=80, sampling_strategy='auto',\n",
    "                                          random_state=0)\n",
    "        \n",
    "    elif modeltype =='BalRF':\n",
    "        from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "        model = BalancedRandomForestClassifier(n_estimators=80, sampling_strategy='auto',\n",
    "                                               max_depth=10, random_state=0,\n",
    "                                              max_features=None, min_samples_leaf=40)\n",
    "\n",
    "    elif modeltype =='Bagged':\n",
    "        from sklearn.ensemble import BaggingClassifier\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        model = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                    n_estimators=40,\n",
    "                                    random_state=0)\n",
    "    \n",
    "    elif modeltype =='RF':\n",
    "        from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "        model = BalancedRandomForestClassifier(n_estimators=60,\n",
    "                                          warm_start = False,\n",
    "                                          max_depth = 10,\n",
    "                                            random_state = 0)\n",
    "    \n",
    "    \n",
    "    # Create framework to predict whether a given census block has a fire risk score in the 90th percentile \n",
    "            # based on the specific number of previous years' data\n",
    "        \n",
    "    years = top10.columns\n",
    "    \n",
    "    \n",
    "    start_pointer = 0\n",
    "    end_pointer = nyears-1\n",
    "    y_pointer = nyears\n",
    "    while y_pointer < len(years):\n",
    "        X_start, X_end = start_pointer, end_pointer\n",
    "       \n",
    "        X = fires.iloc[:,X_start:X_end].copy()\n",
    "            \n",
    "        L = X.shape[1] \n",
    "        X.columns = ['year-{}'.format(L - year) for year in range(L)]\n",
    "        \n",
    "        sm = np.sum(X, axis = 1 )\n",
    "        mu = np.mean(X, axis = 1)\n",
    "        mx = np.max(X, axis =1)\n",
    "        X['Sum']  = sm\n",
    "        X['Mean'] = mu\n",
    "        X['Max']  = mx\n",
    "        y = top10.iloc[:,y_pointer]\n",
    "    \n",
    "        # merge in ACS Data into X unless NFIRS-Only model\n",
    "        if not ACS.empty:\n",
    "            X=X[['Sum','Mean','Max']] # drop all other NFIRS columns that have low feature importance scores\n",
    "            X = X.merge(ACS, how ='left',left_index = True, right_index = True)\n",
    "            X = X.dropna()\n",
    "            y = y.filter(X.index)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create 80/20 training/testing set split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = .2 )\n",
    "        \n",
    "        # Perform resampling if data classes are unbalanced\n",
    "        X_train, y_train = resample_df(X_train,y_train)\n",
    "    \n",
    "    \n",
    "        # Perform cross-validation \n",
    "        \n",
    "        #scaler = preprocessing.StandardScaler().fit(X)\n",
    "        #scaler.transform(X)\n",
    "        #print ('Cross Val Score:')\n",
    "        #print(cross_val_score(model, X, y))\n",
    "        \n",
    "        \n",
    "        # Standardize features by removing the mean and scaling to unit variance\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        scaler.transform(X_train)\n",
    "        scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        # Fit model to training set\n",
    "        \n",
    "        print('Predicting {}:'.format(years[y_pointer]) )\n",
    "        model = model.fit(X_train,y_train)\n",
    "\n",
    "        \n",
    "        # Calculate training set performance\n",
    "        \n",
    "        train_prediction_probs = model.predict_proba(X_train)\n",
    "        train_predictions = model.predict(X_train)\n",
    "        print (confusion_matrix(y_train, train_predictions))\n",
    "        print (roc_auc_score(y_train, train_prediction_probs[:,1]))\n",
    "        \n",
    "        \n",
    "        # Calculate test set performance\n",
    "        \n",
    "        test_prediction_probs = model.predict_proba(X_test)\n",
    "        test_predictions = model.predict(X_test)\n",
    "        print (confusion_matrix(y_test, test_predictions))\n",
    "        print (roc_auc_score(y_test, test_prediction_probs[:,1]))\n",
    "        print (classification_report(y_test,test_predictions))\n",
    "        print (log_loss(y_test,test_predictions))\n",
    "        \n",
    "        \n",
    "        #Calculate feature importance for each model\n",
    "        \n",
    "        if modeltype==\"LogisticRegression\":\n",
    "            feature_importance = {}\n",
    "            for coef, feat in zip(abs(model.coef_[0]),X_test.columns.tolist()):\n",
    "                feature_importance[feat] = coef\n",
    "            print(\"Feature ranking:\")\n",
    "            print (feature_importance)\n",
    "        else:\n",
    "            if modeltype==\"RF\" or modeltype==\"BalRF\":\n",
    "                importances = model.feature_importances_\n",
    "            elif modeltype==\"Bagged\":\n",
    "                importances = np.mean([model.estimators_[i].feature_importances_ for i \n",
    "                               in range(len(model.estimators_))], axis=0)\n",
    "            elif modeltype==\"BalBagged\":\n",
    "                importances = np.mean([model.estimators_[i].steps[1][1].feature_importances_ for i \n",
    "                               in range(len(model.estimators_))], axis=0)\n",
    "        \n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            print(\"Feature ranking:\")\n",
    "            for f in range(len(X_test.columns)):\n",
    "                print(\"%d. %s (%f)\" % (f + 1, X_test.columns[indices[f]], importances[indices[f]]))\n",
    "        \n",
    "        # Increment sliding prediction window\n",
    "        #start_pointer += 1\n",
    "        end_pointer += 1\n",
    "        y_pointer += 1\n",
    "    \n",
    "    \n",
    "            \n",
    "    return model,X_test,y_test,X\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train NFIRS Only Model and output prediction performance metrics for each year\n",
    "# mdl,X_test,y_test=train_model(top10.loc[:,'2009':'2016'],fires,nyears = 5, modeltype='RF', resample = True)\n",
    "\n",
    "# Train NFIRS + ACS Model and output prediction performance metrics for each year\n",
    "mdl,X_test,y_test, X =train_model(top10.loc[:,'2009':'2016'],fires,ACS = ACS,nyears=5, modeltype='BalRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize relative feature importance for trained Logistic Regression models\n",
    "def plot_LR_feat_importance(model):\n",
    "    # Calculate and store relative importance of model features\n",
    "    feature_importance = {}\n",
    "    for coef, feat in zip(abs(model.coef_[0]),X_test.columns.tolist()):\n",
    "        feature_importance[feat] = coef\n",
    "    data_to_plot = pd.DataFrame.from_dict(features,orient ='index').reset_index()\n",
    "    data_to_plot.columns = ['Variables','Importance Coefficients']\n",
    "    data_to_plot = data_to_plot.sort_values('Importance Coefficients', ascending=False )\n",
    "    data_to_plot = data_to_plot[0:10]\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.barplot(\n",
    "        x='Variables', y='Importance Coefficients',\n",
    "        data=data_to_plot, palette='Blues_r')\n",
    "    plt.xticks(\n",
    "        range(len(data_to_plot)),\n",
    "        data_to_plot['Variables'], rotation='45', size=10)\n",
    "    plt.xlabel('Variables', fontsize=30)\n",
    "    plt.ylabel('Coeff', fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display list of relative feature importance for RF models\n",
    "def rf_feat_importance(model, num_feats_to_display):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "    for f in range(num_feats_to_display):\n",
    "        print(\"%d. %s (%f)\" % (f + 1, X_test.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize example tree from random forest (only functional if model max_depth<=5)\n",
    "def plot_rf_tree(model):\n",
    "    estimator = model.estimators_[1]\n",
    "    from sklearn import tree\n",
    "    fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
    "    tree.plot_tree(estimator,\n",
    "               feature_names = X_test.columns, \n",
    "               class_names=y_test.index.name,\n",
    "               filled = True);\n",
    "    fig.savefig('rf_individualtree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(X,y, test_size=0.2, seed=SEED):\n",
    "    \n",
    "    from scipy.stats import zscore\n",
    "    \n",
    "    \n",
    "    X = np.log(X +1)\n",
    "    y = np.log(y+1)\n",
    "    \n",
    "    print (X.shape)\n",
    "   # rename features and add new features\n",
    "    X.columns = ['year-{}'.format(year[0]+1) for year in enumerate(X.columns)]\n",
    "    X.columns\n",
    "    X['Sum'] = np.sum(X, axis = 1 )\n",
    "    X['mean']= np.mean(X, axis = 1)\n",
    "    X['median'] = np.median(x, axis = 1)\n",
    "    \n",
    "    \n",
    "    X = zscore(X.astype(float), axis=0)\n",
    "    \n",
    "    \n",
    " \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=seed)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundaries(X,y,model,n):\n",
    "        \n",
    "    from itertools import combinations\n",
    "    n_elms = max(y.shape[0],1000) # only plot 1000 elements from each class\n",
    "    \n",
    "    n_cols = np.ceil(np.sqrt(n))\n",
    "    n_rows = np.ceil(n / n_cols)\n",
    "\n",
    "    names = X.columns\n",
    "    combos = [c for c in combinations(range(X.shape[1]), 2) ]\n",
    "    \n",
    "    W = model.coef_[0]\n",
    "        \n",
    "\n",
    "    b = model.intercept_\n",
    "    \n",
    "    for c in enumerate(combos[:n]):\n",
    "        x_idx = c[1][0]\n",
    "        y_idx = c[1][1]\n",
    "        plot_num = c[0]\n",
    "            \n",
    "            \n",
    "        print('subplot{} {}: {}'.format(n_rows,n_cols,c[0]))\n",
    "        plt.subplot(n_rows,n_cols,c[0]+1)\n",
    "        plt.scatter(X.iloc[:n_elms, x_idx],\n",
    "                    X.iloc[:n_elms, y_idx],\n",
    "                    c=y[:n_elms], edgecolors='k',\n",
    "                    alpha = .3, cmap=plt.cm.binary)\n",
    "        \n",
    "        ax = plt.gca()\n",
    "\n",
    "        x_values = np.array(ax.get_xlim())\n",
    "        y_values = -(b + np.dot(W[x_idx],x_values)) / W[y_idx]\n",
    "\n",
    "        plt.plot(x_values, y_values )\n",
    "\n",
    "\n",
    "        plt.xticks(())\n",
    "        plt.xlabel(names[x_idx])\n",
    "        plt.yticks(())\n",
    "        plt.ylabel(names[y_idx])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_boundaries(X_test,y_test,mdl,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.multivariate_normal([0,0,0,0],np.identity(4),1000)\n",
    "x[0:500,2] += 5\n",
    "x[0:500,3] -= 5\n",
    "x[:500,1] += -1\n",
    "x[:500,0] -= 10\n",
    "y = np.zeros([1000,])\n",
    "y[:500] = 1 \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tmdl = LogisticRegression().fit(x,y)\n",
    "\n",
    "x =pd.DataFrame(data = x,columns={'0','1','2','3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_boundaries(x,y,tmdl,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " from itertools import combinations\n",
    "c= [c for c in combinations(range(5),2)]\n",
    "\n",
    "for a in enumerate(c[:5]):\n",
    "    print(a[0],a[1], a[1][0],a[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_clf_model(data, model='LogisticRegression', seed=0, verbose=True, variables=None):\n",
    "    _allowed_models = [\"LogisticRegression\", \"SVM\", \"Tree\", \"RandomForest\"]\n",
    "    assert model in _allowed_models, \"Invalid model name entered. Allowed options: %s\" % _allowed_models\n",
    "\n",
    "    X_train, X_test, y_train, y_test = process_data(data, variables)\n",
    "\n",
    "    if verbose:\n",
    "        print('-' * 90)\n",
    "        print('[PROGRESS] Training %s classifier...' % model)\n",
    "    \n",
    "    if model == 'LogisticRegression':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        clf = LogisticRegression(\n",
    "            solver='lbfgs', max_iter=1000,\n",
    "            random_state=seed,\n",
    "        ).fit(X_train, y_train)\n",
    "\n",
    "    elif model == 'SVM':\n",
    "        from sklearn.svm import SVC\n",
    "        clf = SVC(\n",
    "            gamma='auto',\n",
    "            kernel='linear',\n",
    "            random_state=seed,\n",
    "        ).fit(X_train, y_train)\n",
    "    \n",
    "    elif model == 'Tree':\n",
    "        from sklearn import tree\n",
    "        clf = tree.DecisionTreeClassifier(\n",
    "            random_state=seed,\n",
    "        ).fit(X_train,y_train)\n",
    "        \n",
    "    elif model == 'RandomForest':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=seed,\n",
    "        ).fit(X_train,y_train)\n",
    "    else:\n",
    "        raise(NotImplemented)\n",
    "\n",
    "    if verbose:\n",
    "        print('[PROGRESS] ...done!')\n",
    "        msg = \"\\n[INFO] Train accuracy: {0:.1f} %,    Test accuracy: {1:.1f} %\".format(\n",
    "            clf.score(X_train, y_train) * 100, clf.score(X_test, y_test) * 100)\n",
    "        print(msg)\n",
    "        print('-' * 90)\n",
    "        print('\\n')\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train severe model\n",
    "sev_mdl, sev_X_test, sev_y_test, sev_X =train_model(sev_top10.loc[:,'2009':'2016'],sev_fires,ACS = ACS,nyears=5, modeltype='BalRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataframe with both feature importances\n",
    "def feature_impt_df(model, X_test, col_name):\n",
    "    importances = model.feature_importances_\n",
    "    features = pd.DataFrame(importances, columns=[col_name])\n",
    "    features['feature_name'] = X_test.columns\n",
    "    features = features[['feature_name', col_name]]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = feature_impt_df(mdl, X_test, 'all_fires')\n",
    "sev_features = feature_impt_df(sev_mdl, sev_X_test, 'severe_fires')\n",
    "feature_comp = pd.merge(all_features, sev_features)\n",
    "feature_comp.set_index('feature_name', inplace=True)\n",
    "\n",
    "feature_comp.to_csv('all_vs_severe_feature_importances.csv')\n",
    "\n",
    "feature_comp.sort_values('all_fires', inplace=True)\n",
    "feature_comp.plot(kind='barh', title='Feature Importances All vs Severe Fires', figsize=(12,8))\n",
    "plt.savefig('feature_imp_comp.png', replace=True)\n",
    "\n",
    "# temp = feature_comp.copy()\n",
    "# temp.loc['Max', 'all_fires'] = temp.loc['Max', 'severe_fires']\n",
    "# temp.plot(kind='barh', title='Feature Importances All vs Severe Fires (trimmed)', figsize=(12,8))\n",
    "# plt.savefig('feature_imp_comp_trimmed.png', replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare predictions\n",
    "all_comp = pd.DataFrame(y_test)\n",
    "all_comp.rename({'2016': 'true_all_fires'}, axis='columns', inplace=True)\n",
    "all_yhat = mdl.predict(X_test)\n",
    "all_comp['pred_all_fires'] = all_yhat\n",
    "display(all_comp.shape)\n",
    "\n",
    "sev_comp = pd.DataFrame(sev_y_test)\n",
    "sev_comp.rename({'2016': 'true_sev_fires'}, axis='columns', inplace=True)\n",
    "sev_yhat = sev_mdl.predict(sev_X_test)\n",
    "sev_comp['pred_sev_fires'] = sev_yhat\n",
    "display(sev_comp.shape)\n",
    "\n",
    "pred_comp = pd.merge(all_comp, sev_comp, left_index=True, right_index=True)\n",
    "pred_comp.to_csv('all_vs_severe_predictions.csv')\n",
    "display(pred_comp.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = pred_comp.groupby(['true_all_fires', 'true_sev_fires', 'pred_all_fires']).count().reset_index()\n",
    "pred_all.rename({'pred_sev_fires': 'pred_all'}, axis='columns', inplace=True)\n",
    "pred_all = pred_all.set_index(['true_all_fires', 'true_sev_fires', 'pred_all_fires']).unstack()\n",
    "pred_all.reset_index(inplace=True)\n",
    "pred_all.columns = ['true_all_fires', 'true_sev_fires', 'pred_all_false', 'pred_all_true']\n",
    "\n",
    "pred_sev = pred_comp.groupby(['true_all_fires', 'true_sev_fires', 'pred_sev_fires']).count().reset_index()\n",
    "pred_sev.rename({'pred_all_fires': 'pred_sev'}, axis='columns', inplace=True)\n",
    "pred_sev = pred_sev.set_index(['true_all_fires', 'true_sev_fires', 'pred_sev_fires']).unstack()\n",
    "pred_sev.reset_index(inplace=True)\n",
    "pred_sev.columns = ['true_all_fires', 'true_sev_fires', 'pred_sev_false', 'pred_sev_true']\n",
    "\n",
    "pred = pd.merge(pred_all, pred_sev)\n",
    "pred['total'] = pred[['pred_all_false', 'pred_all_true']].sum(axis=1)\n",
    "pred = pred[['true_all_fires', 'true_sev_fires', 'total', 'pred_all_false', 'pred_all_true', 'pred_sev_false', 'pred_sev_true']]\n",
    "pred.to_csv('all_vs_severe_predictions_counts.csv', index=False)\n",
    "display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yhat = mdl.predict(X)\n",
    "sev_yhat = sev_mdl.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame(all_yhat)\n",
    "comp['severe'] = sev_yhat\n",
    "comp.columns = ['all', 'severe']\n",
    "comp['dummy'] = 1\n",
    "comp['count'] = comp.groupby(['all', 'severe']).transform('count')['dummy']\n",
    "comp.drop_duplicates(inplace=True)\n",
    "comp.drop('dummy', axis=1, inplace=True)\n",
    "comp.sort_values('all', inplace=True)\n",
    "display(comp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('dk': venv)",
   "language": "python",
   "name": "python37664bitdkvenvd6a5ec372db94c2b99f619fe1cc69626"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}